{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive analysis: Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T07:06:33.864226Z",
     "start_time": "2024-06-19T07:06:33.856272Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "from time import strftime, gmtime\n",
    "from datetime import datetime\n",
    "import os\n",
    "from hdfs import InsecureClient\n",
    "\n",
    "import re\n",
    "import os\n",
    "from time import strftime, gmtime\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "import findspark\n",
    "import warnings\n",
    "from pyspark.sql.functions import split, col, avg, count\n",
    "from pyspark.ml.feature import FeatureHasher\n",
    "\n",
    "import pyspark as py\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read login information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T07:06:36.500551Z",
     "start_time": "2024-06-19T07:06:36.488968Z"
    }
   },
   "outputs": [],
   "source": [
    "%run utils.py\n",
    "\n",
    "log = log_config(\"My.log\")\n",
    "logging_info = logging_creation()\n",
    "\n",
    "user_name = logging_info[\"user_name\"]\n",
    "host = logging_info[\"host\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data from formatted zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T07:06:38.774880Z",
     "start_time": "2024-06-19T07:06:38.766635Z"
    }
   },
   "outputs": [],
   "source": [
    "%run data_SelectorsAndFormatters.py\n",
    "\n",
    "inp_path=\"model_temp\"\n",
    "master_files = {\n",
    "    \"hotels\": {\"Description\": \"Information about hotels in neighbourhoods\"},\n",
    "    \"renda_familiar\": {\n",
    "        \"keywords\": [\"renda_familiar\"],\n",
    "        \"Description\": \"Data from Open Barcelona with incomes of families. Can be joined with 'idealista' file using a lookup file\",\n",
    "    },\n",
    "    \"idealista\": {\n",
    "        \"keywords\": [\"idealista\"],\n",
    "        \"Description\": \"Appartments from idealista. Can be joined with 'renta familiar' file using a lookup file\",\n",
    "    },\n",
    "    \"lookup_renta_idealista\": {\n",
    "        \"keywords\": [\"extended\"],\n",
    "        \"Description\": \"Lookup datable to join 'Idealista' and 'renda familiar'\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load last versions of all dataframes from explotation zone\n",
    "for key_file in master_files.keys():\n",
    "    formatted_data_selector(log, user_name, host, key_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:22:35.027620Z",
     "start_time": "2024-06-19T10:22:34.997094Z"
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/Users/yyf/Documents/Spark\")\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"Dashboard\")\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:22:37.123155Z",
     "start_time": "2024-06-19T10:22:36.934276Z"
    }
   },
   "outputs": [],
   "source": [
    "inp_path = \"model_temp\"  # make sure to define inp_path\n",
    "file_names = os.listdir(inp_path)\n",
    "dfs = {}\n",
    "\n",
    "for file in file_names:\n",
    "    full_in_path = os.path.join(inp_path, file)\n",
    "    # Assuming the naming pattern is consistent and you're interested in the part after the second dash\n",
    "    short_name = file.split(\"-\", maxsplit=2)[2].replace(\".parquet\", \"\")\n",
    "    dfs[short_name] = spark.read.option(\"multiline\", \"true\").format(\"parquet\").load(full_in_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:22:37.647937Z",
     "start_time": "2024-06-19T10:22:37.644370Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_fields = {\n",
    "    \"renda_familiar\": [\n",
    "            \"Nom_Districte\",\n",
    "            \"Codi_Districte\",\n",
    "            \"Índex RFD Barcelona = 100\",\n",
    "        ],\n",
    "        \"idealista\": [\"district\", \"priceByArea\",\"price\"],\n",
    "        \"lookup_renta_idealista\": [\"district\", \"district_id\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:22:38.379028Z",
     "start_time": "2024-06-19T10:22:38.351975Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, split\n",
    "\n",
    "# Dropping rows with null values in selected fields\n",
    "for key in dfs:\n",
    "    if key in selected_fields:\n",
    "        dfs[key] = dfs[key].na.drop(subset=selected_fields[key])\n",
    "\n",
    "# modify the certain variables, delete \"\"\n",
    "dfs[\"renda_familiar\"] = dfs[\"renda_familiar\"].withColumn(\n",
    "    \"Nom_Districte\", split(col(\"Nom_Districte\"), '\"')[1]\n",
    ").withColumn(\n",
    "    \"Índex RFD Barcelona = 100\", split(col(\"Índex RFD Barcelona = 100\"), '\"')[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload preprocessed dataframe to the explotation zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:29:55.747588Z",
     "start_time": "2024-06-19T10:29:55.703351Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "dfs[\"dashboard\"] = dfs[\"idealista\"].join(\n",
    "    dfs[\"renda_familiar\"],\n",
    "    col(\"district\") == col(\"Nom_Districte\"),  \n",
    "    \"inner\"\n",
    ").select(\n",
    "    col(\"district\").alias(\"district_idealista\"),  \n",
    "    col(\"priceByArea\").alias(\"priceByArea_idealista\"),\n",
    "    col(\"price\").alias(\"price_idealista\"),\n",
    "    col(\"Nom_Districte\").alias(\"Nom_Districte_renda\"),  \n",
    "    col(\"Codi_Districte\").alias(\"Codi_Districte_renda\"),  \n",
    "    col(\"Índex RFD Barcelona = 100\").alias(\"Index_RFD_renda\")  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:30:24.006516Z",
     "start_time": "2024-06-19T10:30:24.004030Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"dashboard.parquet\"\n",
    "\n",
    "explotation_zone_path = \"user/bdm/Model_explotation_zone_dashboard\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:30:27.986552Z",
     "start_time": "2024-06-19T10:30:25.829255Z"
    }
   },
   "outputs": [],
   "source": [
    "hdfs_client = InsecureClient(host, user=user_name)\n",
    "out_full_path = explotation_zone_path + \"/\" + model_name \n",
    "\n",
    "dfs[\"dashboard\"].write.parquet(model_name)\n",
    "\n",
    "hdfs_client.upload(out_full_path, model_name, overwrite=True)\n",
    "\n",
    "log.info(f\"Model {file} uploaded correctly at '{out_full_path}' path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to csv to do the dashboard in Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_path = \"csv\"\n",
    "\n",
    "# Save 'renda_familiar' DataFrame with selected columns\n",
    "dfs[\"renda_familiar\"].select(\n",
    "    \"Nom_Districte\",\n",
    "    \"Codi_Districte\",\n",
    "    \"Índex RFD Barcelona = 100\"\n",
    ").write.option(\"header\", True).mode(\"overwrite\").csv(os.path.join(output_path, \"renda_familiar\"))\n",
    "\n",
    "# Save 'idealista' DataFrame with selected columns\n",
    "dfs[\"idealista\"].select(\n",
    "    \"district\",\n",
    "    \"priceByArea\",\n",
    "    \"price\"\n",
    ").write.option(\"header\", True).mode(\"overwrite\").csv(os.path.join(output_path, \"idealista\"))\n",
    "\n",
    "# Save 'lookup_renta_idealista' DataFrame with selected columns\n",
    "dfs[\"lookup_renta_idealista\"].select(\n",
    "    \"district\",\n",
    "    \"district_id\"\n",
    ").write.option(\"header\", True).mode(\"overwrite\").csv(os.path.join(output_path, \"lookup_renta_idealista\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
